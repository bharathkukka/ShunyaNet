# Quick Reference Checklist âœ…

## When Training Your Model

```
âœ… DO:
â”œâ”€â”€ Load train data from: Data/PaddyDiseases/Dataset/train/
â”œâ”€â”€ Load val data from:   Data/PaddyDiseases/Dataset/val/
â”œâ”€â”€ Train on train data
â”œâ”€â”€ Evaluate on val data
â”œâ”€â”€ Report val accuracy in your results
â””â”€â”€ Save best model based on val performance

âŒ DON'T:
â”œâ”€â”€ Load test data during training
â”œâ”€â”€ Try to evaluate on test data
â”œâ”€â”€ Report test accuracy (you can't calculate it!)
â””â”€â”€ Touch test folder until model is completely done
```

## Your Model Performance Metrics

```python
# What to report:
print(f"Training Accuracy:   {train_acc:.2f}%")
print(f"Validation Accuracy: {val_acc:.2f}%")   â† THIS IS YOUR MAIN METRIC!

# What NOT to report:
# print(f"Test Accuracy: ???")  â† You don't know this!
```

## When to Use Test Data

**ONLY after:**
- âœ… Model is fully trained
- âœ… Model is fully evaluated (on validation)
- âœ… You're satisfied with validation performance
- âœ… You want to submit to Kaggle

**Then:**
```python
from test_data_utils import UnlabeledTestDataset, predict_test_set

# Generate predictions (you won't know if they're correct!)
predictions = predict_test_set(model, test_loader, device, class_names)

# Create submission file
create_submission_file(predictions, 'submission.csv')

# Submit to Kaggle â†’ They tell you the score
```

---

## Your Current Setup âœ…

```
âœ… Train set created:      9,371 images (labeled)
âœ… Validation set created: 1,036 images (labeled)
âœ… Test set exists:        3,469 images (unlabeled - ignore for now!)
âœ… Ready to train!
```

---

## Simple Training Template

```python
# Step 1: Load ONLY train and val
train_dataset = ImageFolder('Data/PaddyDiseases/Dataset/train', transform=train_transform)
val_dataset = ImageFolder('Data/PaddyDiseases/Dataset/val', transform=val_transform)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

# Step 2: Train and evaluate
best_val_acc = 0
for epoch in range(num_epochs):
    train_loss = train_epoch(model, train_loader)
    val_loss, val_acc = evaluate(model, val_loader)
    
    if val_acc > best_val_acc:
        best_val_acc = val_acc
        torch.save(model.state_dict(), 'best_model.pth')
    
    print(f"Epoch {epoch}: Val Acc = {val_acc:.2f}%")

# Step 3: Report results
print(f"\nFinal Validation Accuracy: {best_val_acc:.2f}%")  â† THIS!

# Step 4: (Optional) Generate test predictions for Kaggle
# ... only do this after model is completely done!
```

---

## Files You Have Now

```
ShunyaNet/Paddy-Disease-Recognition/
â”œâ”€â”€ DataArrange.py           â† Run this to analyze dataset
â”œâ”€â”€ test_data_utils.py       â† Use this when ready for test predictions
â”œâ”€â”€ README.md                â† Full documentation
â”œâ”€â”€ PROBLEM_SUMMARY.md       â† Quick problem explanation
â”œâ”€â”€ WORKFLOW_EXPLAINED.md    â† Detailed workflow (what you understood!)
â””â”€â”€ CHECKLIST.md             â† This file (quick reference)
```

---

## Remember

**Your understanding is PERFECT! âœ…**

> Test data is just for predictions that you don't know are correct.
> Kaggle will tell you how well your model did on test data.
> For now (during development), test data is useless.
> Validation accuracy is your performance metric!

**Now go train that model! ðŸš€**

